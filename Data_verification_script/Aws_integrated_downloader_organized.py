#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AWSç»Ÿåˆãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆãƒ•ã‚©ãƒ«ãƒ€ç®¡ç†ç‰ˆï¼‰
DynamoDB ã¨ Timestream ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€æ•´ç†ã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜
â–  ä½¿ã„æ–¹
python aws_integrated_downloader_organized.py --user "azlm-prd-004@01ive.co.jp" --company "azlm-prd" --start "2025-09-04 23:00:00" --end "2025-09-04 23:30:00"
"""

import boto3
import pandas as pd
import json
import argparse
from datetime import datetime, timedelta
from boto3.dynamodb.conditions import Key, Attr
import os
import sys
import logging
from typing import List, Dict, Optional, Tuple
from botocore.exceptions import NoCredentialsError, ClientError, BotoCoreError

class OrganizedAWSDownloader:
    def __init__(self, csv_key_path='shibo-chen_accessKeys.csv', region_name='ap-northeast-1'):
        """
        æ•´ç†ã•ã‚ŒãŸAWSãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–
        """
        self.csv_key_path = csv_key_path
        self.region_name = region_name
        self.dynamodb_table_name = 'dev_lacause_emotion_user_tracking_v1'
        self.timestream_database = 'prd_lacause_emotion_data_v1'
        self.timestream_table = 'lacause_emotion'
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
        # AWSèªè¨¼ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self._setup_aws_clients()
        
    def _setup_aws_clients(self):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰AWSèªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¨­å®š"""
        try:
            if not os.path.exists(self.csv_key_path):
                raise FileNotFoundError(f"AWSã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.csv_key_path}")
            
            keys_df = pd.read_csv(self.csv_key_path)
            if keys_df.empty:
                raise ValueError("CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
            
            access_key_id = keys_df.iloc[0]['Access key ID']
            secret_access_key = keys_df.iloc[0]['Secret access key']
            
            self.logger.info(f"AWSã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {access_key_id[:10]}...")
            
            # å„ç¨®AWSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
            self._init_dynamodb_client(access_key_id, secret_access_key)
            self._init_timestream_client(access_key_id, secret_access_key)
            
        except Exception as e:
            self.logger.error(f"AWSèªè¨¼è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)
    
    def _init_dynamodb_client(self, access_key_id, secret_access_key):
        """DynamoDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            self.dynamodb_resource = boto3.resource(
                'dynamodb',
                region_name=self.region_name,
                aws_access_key_id=access_key_id,
                aws_secret_access_key=secret_access_key
            )
            
            self.dynamodb_client = boto3.client(
                'dynamodb',
                region_name=self.region_name,
                aws_access_key_id=access_key_id,
                aws_secret_access_key=secret_access_key
            )
            
            self.dynamodb_table = self.dynamodb_resource.Table(self.dynamodb_table_name)
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            table_info = self.dynamodb_client.describe_table(TableName=self.dynamodb_table_name)
            self.dynamodb_available = True
            self.logger.info(f"âœ… DynamoDBã«æ¥ç¶šæˆåŠŸ: {self.dynamodb_table_name}")
            
        except Exception as e:
            self.dynamodb_available = False
            self.logger.warning(f"âš ï¸ DynamoDBæ¥ç¶šå¤±æ•—: {e}")
    
    def _init_timestream_client(self, access_key_id, secret_access_key):
        """Timestreamã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            self.timestream_client = boto3.client(
                'timestream-query',
                region_name=self.region_name,
                aws_access_key_id=access_key_id,
                aws_secret_access_key=secret_access_key
            )
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆç°¡å˜ãªã‚¯ã‚¨ãƒªï¼‰
            test_query = f'SELECT COUNT(*) FROM "{self.timestream_database}"."{self.timestream_table}" WHERE time > ago(1d) LIMIT 1'
            self.timestream_client.query(QueryString=test_query)
            
            self.timestream_available = True
            self.logger.info(f"âœ… Timestreamã«æ¥ç¶šæˆåŠŸ: {self.timestream_database}.{self.timestream_table}")
            
        except Exception as e:
            self.timestream_available = False
            self.logger.warning(f"âš ï¸ Timestreamæ¥ç¶šå¤±æ•—: {e}")
    
    def create_output_folder(self, start_time, end_time, company=None):
        """å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ"""
        # å®Ÿè¡Œæ™‚é–“
        request_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ãƒ‡ãƒ¼ã‚¿æœŸé–“
        try:
            start_dt = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')
            end_dt = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')
            
            if start_dt.date() == end_dt.date():
                # åŒã˜æ—¥ã®å ´åˆ
                date_range = start_dt.strftime("%Y%m%d")
            else:
                # ç•°ãªã‚‹æ—¥ã®å ´åˆ
                date_range = f"{start_dt.strftime('%Y%m%d')}_{end_dt.strftime('%Y%m%d')}"
        except:
            date_range = "unknown_date"
        
        # ãƒ•ã‚©ãƒ«ãƒ€åä½œæˆ
        if company:
            folder_name = f"{company}_{date_range}_requested_{request_time}"
        else:
            folder_name = f"data_{date_range}_requested_{request_time}"
        
        # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
        try:
            os.makedirs(folder_name, exist_ok=True)
            self.logger.info(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ: {folder_name}")
            return folder_name
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return "."
    
    def _convert_time_to_timestamp(self, time_str):
        """æ™‚é–“æ–‡å­—åˆ—ã‚’Unixã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¤‰æ›ï¼ˆãƒŸãƒªç§’å˜ä½ï¼‰"""
        try:
            dt = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
            timestamp_ms = int(dt.timestamp() * 1000)
            return timestamp_ms
        except Exception as e:
            self.logger.error(f"æ™‚é–“å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _normalize_user_id(self, user_id):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã®æ­£è¦åŒ–"""
        if user_id and "01live.co.jp" in user_id:
            corrected = user_id.replace("01live.co.jp", "01ive.co.jp")
            self.logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼IDä¿®æ­£: {user_id} â†’ {corrected}")
            return corrected
        return user_id
    
    # ==================== DynamoDBé–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ ====================
    
    def download_from_dynamodb(self, user_id=None, start_time=None, end_time=None, 
                              company=None, event_type=None):
        """DynamoDBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        if not self.dynamodb_available:
            self.logger.error("DynamoDBãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return []
        
        self.logger.info("ğŸ“Š DynamoDBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã®æ­£è¦åŒ–
        user_id = self._normalize_user_id(user_id)
        
        if not user_id:
            self.logger.error("DynamoDBç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼IDãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            response = self.dynamodb_table.query(
                KeyConditionExpression=Key('user_id').eq(user_id),
                Limit=1
            )
            
            if response['Count'] == 0:
                self.logger.warning(f"DynamoDBã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ '{user_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
            
            # åŸºæœ¬ã‚­ãƒ¼æ¡ä»¶
            key_condition = Key('user_id').eq(user_id)
            
            # æ™‚é–“ç¯„å›²ã®è¿½åŠ ï¼ˆinserted_timeãƒ™ãƒ¼ã‚¹ï¼‰
            if start_time and end_time:
                start_timestamp = self._convert_time_to_timestamp(start_time)
                end_timestamp = self._convert_time_to_timestamp(end_time)
                
                if start_timestamp and end_timestamp:
                    # ãƒãƒ¼ã‚¸ãƒ³ã‚’è¿½åŠ 
                    margin_ms = 60000  # 1åˆ†
                    adjusted_start = start_timestamp - margin_ms
                    adjusted_end = end_timestamp + margin_ms
                    
                    key_condition = key_condition & Key('inserted_time').between(adjusted_start, adjusted_end)
            
            # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            items = []
            query_kwargs = {'KeyConditionExpression': key_condition}
            
            while True:
                response = self.dynamodb_table.query(**query_kwargs)
                items.extend(response['Items'])
                
                if 'LastEvaluatedKey' not in response:
                    break
                query_kwargs['ExclusiveStartKey'] = response['LastEvaluatedKey']
            
            # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if start_time and end_time and items:
                filtered_items = []
                for item in items:
                    item_time = item.get('time', '')
                    if item_time and start_time <= item_time <= end_time:
                        filtered_items.append(item)
                items = filtered_items
            
            if company or event_type:
                filtered_items = []
                for item in items:
                    if company and item.get('company') != company:
                        continue
                    if event_type and item.get('event') != event_type:
                        continue
                    filtered_items.append(item)
                items = filtered_items
            
            self.logger.info(f"âœ… DynamoDBã‹ã‚‰ {len(items)} ä»¶å–å¾—")
            return items
            
        except Exception as e:
            self.logger.error(f"âŒ DynamoDBãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    # ==================== Timestreamé–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ ====================
    
    def _query_timestream_with_pagination(self, query):
        """Timestreamã§ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ"""
        try:
            next_token = None
            all_rows = []
            column_info = None
            
            while True:
                # ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ
                if next_token:
                    response = self.timestream_client.query(QueryString=query, NextToken=next_token)
                else:
                    response = self.timestream_client.query(QueryString=query)
                
                # åˆå›ã®ã¿ColumnInfoã‚’å–å¾—
                if column_info is None:
                    column_info = response['ColumnInfo']
                
                # å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                all_rows.extend(response['Rows'])
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ç¢ºèª
                next_token = response.get('NextToken')
                if not next_token:
                    break
            
            return all_rows, column_info
            
        except ClientError as e:
            self.logger.error(f"Timestreamã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e.response['Error']['Message']}")
            return None, None
        except Exception as e:
            self.logger.error(f"TimestreamäºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None, None
    
    def download_from_timestream(self, company=None, start_time=None, end_time=None, timezone_offset=9):
        """Timestreamã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        if not self.timestream_available:
            self.logger.error("TimestreamãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return pd.DataFrame()
        
        if not company:
            self.logger.error("Timestreamç”¨ã®ä¼šç¤¾IDãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return pd.DataFrame()
        
        self.logger.info("â±ï¸ Timestreamã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        try:
            # ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            query = f'''
            SELECT 
                time + {timezone_offset}h AS time, 
                user_id, 
                stress, 
                attention, 
                four_types 
            FROM "{self.timestream_database}"."{self.timestream_table}" 
            WHERE (bin(time,10s) + {timezone_offset}h) BETWEEN '{start_time}' AND '{end_time}'
            AND "company" = '{company}'
            ORDER BY time
            '''
            
            self.logger.info(f"Timestreamã‚¯ã‚¨ãƒªå®Ÿè¡Œä¸­...")
            
            # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            response, column_info = self._query_timestream_with_pagination(query)
            
            if not response:
                self.logger.warning("Timestreamã‚¯ã‚¨ãƒªã®çµæœãŒ0ä»¶ã§ã™")
                return pd.DataFrame()
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
            processed_data = []
            for entry in response:
                processed_row = [item['ScalarValue'] for item in entry['Data']]
                processed_data.append(processed_row)
            
            # DataFrameã®ä½œæˆ
            columns = ['time', 'user_id', 'stress', 'attention', 'four_types']
            df = pd.DataFrame(processed_data, columns=columns)
            
            # å‹ã®å¤‰æ›
            df['time'] = pd.to_datetime(df['time']).dt.floor('S')
            df['stress'] = pd.to_numeric(df['stress'], errors='coerce')
            df['attention'] = pd.to_numeric(df['attention'], errors='coerce')
            df['four_types'] = pd.to_numeric(df['four_types'], errors='coerce')
            
            # æ—¥æ™‚æƒ…å ±ã‚’è¿½åŠ 
            df['day'] = df['time'].dt.strftime('%Y/%m/%d')
            df['hour'] = df['time'].dt.hour
            df['minutes'] = df['time'].dt.minute
            
            # åˆ—ã®ä¸¦ã³æ›¿ãˆ
            df = df[['time', 'day', 'hour', 'minutes', 'stress', 'attention', 'four_types', 'user_id']]
            
            self.logger.info(f"âœ… Timestreamã‹ã‚‰ {len(df)} ä»¶å–å¾—")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ Timestreamãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    # ==================== ãƒ‡ãƒ¼ã‚¿ä¿å­˜é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ ====================
    
    def save_dynamodb_data(self, items, output_folder, filename_base):
        """DynamoDBãƒ‡ãƒ¼ã‚¿ã‚’CSVã®ã¿ä¿å­˜"""
        if not items:
            self.logger.info("DynamoDBãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return []
        
        saved_files = []
        
        try:
            # CSVä¿å­˜ã®ã¿
            df = pd.json_normalize(items)
            csv_filename = os.path.join(output_folder, f"{filename_base}_dynamodb.csv")
            df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
            saved_files.append(csv_filename)
            
            file_size = os.path.getsize(csv_filename) / 1024
            self.logger.info(f"ğŸ’¾ DynamoDB CSVä¿å­˜: {csv_filename} ({file_size:.1f} KB)")
            
        except Exception as e:
            self.logger.error(f"DynamoDBãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        return saved_files
    
    def save_timestream_data(self, df, output_folder, filename_base):
        """Timestreamãƒ‡ãƒ¼ã‚¿ã‚’CSVã®ã¿ä¿å­˜"""
        if df.empty:
            self.logger.info("Timestreamãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return []
        
        saved_files = []
        
        try:
            # CSVä¿å­˜ã®ã¿
            csv_filename = os.path.join(output_folder, f"{filename_base}_timestream.csv")
            df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
            saved_files.append(csv_filename)
            
            file_size = os.path.getsize(csv_filename) / 1024
            self.logger.info(f"ğŸ’¾ Timestream CSVä¿å­˜: {csv_filename} ({file_size:.1f} KB)")
            
            
        except Exception as e:
            self.logger.error(f"Timestreamãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        return saved_files
    
    def download_all_data(self, user_id=None, company=None, start_time=None, end_time=None, 
                         event_type=None, timezone_offset=9):
        """ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰çµ±åˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        
        self.logger.info("ğŸš€ çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
        self.logger.info(f"ğŸ“‹ æ¡ä»¶: ãƒ¦ãƒ¼ã‚¶ãƒ¼={user_id}, ä¼šç¤¾={company}, æ™‚é–“={start_time}~{end_time}")
        
        # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
        output_folder = self.create_output_folder(start_time, end_time, company)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ™ãƒ¼ã‚¹ä½œæˆ
        if company:
            filename_base = f"{company}"
        else:
            filename_base = "data"
        
        all_saved_files = []
        
        # 1. DynamoDBã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if self.dynamodb_available:
            try:
                self.logger.info("ğŸ“Š DynamoDBãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹...")
                dynamodb_items = self.download_from_dynamodb(
                    user_id=user_id, 
                    start_time=start_time, 
                    end_time=end_time,
                    company=company, 
                    event_type=event_type
                )
                saved_files = self.save_dynamodb_data(dynamodb_items, output_folder, filename_base)
                all_saved_files.extend(saved_files)
            except Exception as e:
                self.logger.error(f"DynamoDBå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 2. Timestreamã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if self.timestream_available and company:
            try:
                self.logger.info("â±ï¸ Timestreamãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹...")
                timestream_df = self.download_from_timestream(
                    company=company,
                    start_time=start_time,
                    end_time=end_time,
                    timezone_offset=timezone_offset
                )
                saved_files = self.save_timestream_data(timestream_df, output_folder, filename_base)
                all_saved_files.extend(saved_files)
            except Exception as e:
                self.logger.error(f"Timestreamå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        # READMEãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        self._create_readme_file(output_folder, user_id, company, start_time, end_time, all_saved_files)
        
        # çµæœã‚µãƒãƒªãƒ¼
        self.logger.info("="*60)
        self.logger.info("ğŸ‰ çµ±åˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        self.logger.info(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_folder}")
        if all_saved_files:
            self.logger.info("ğŸ“„ ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
            for file in all_saved_files:
                file_size = os.path.getsize(file) / 1024 if os.path.exists(file) else 0
                rel_path = os.path.relpath(file, output_folder)
                self.logger.info(f"  - {rel_path} ({file_size:.1f} KB)")
        else:
            self.logger.warning("âš ï¸ ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        self.logger.info("="*60)
        
        return output_folder, all_saved_files
    
    def _create_readme_file(self, output_folder, user_id, company, start_time, end_time, saved_files):
        """READMEãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        try:
            readme_path = os.path.join(output_folder, "README.txt")
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write("AWS ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ\n")
                f.write("=" * 40 + "\n\n")
                
                f.write("ğŸ“‹ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¡ä»¶:\n")
                f.write(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {user_id or 'N/A'}\n")
                f.write(f"  ä¼šç¤¾ID: {company or 'N/A'}\n")
                f.write(f"  é–‹å§‹æ™‚é–“: {start_time}\n")
                f.write(f"  çµ‚äº†æ™‚é–“: {end_time}\n")
                f.write(f"  å®Ÿè¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("ğŸ“„ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:\n")
                for file in saved_files:
                    rel_path = os.path.relpath(file, output_folder)
                    file_size = os.path.getsize(file) / 1024 if os.path.exists(file) else 0
                    f.write(f"  - {rel_path} ({file_size:.1f} KB)\n")
                
                f.write("\nğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«èª¬æ˜:\n")
                f.write("  - *_dynamodb.csv: DynamoDBã‹ã‚‰ã®é¡”æ¤œå‡ºãƒ‡ãƒ¼ã‚¿\n")
                f.write("  - *_timestream.csv: Timestreamã‹ã‚‰ã®æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿\n")
            
            self.logger.info(f"ğŸ“‹ READMEä½œæˆ: {readme_path}")
            
        except Exception as e:
            self.logger.error(f"READMEä½œæˆã‚¨ãƒ©ãƒ¼: {e}")

def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ"""
    parser = argparse.ArgumentParser(
        description='AWSçµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆæ•´ç†ç‰ˆï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  python %(prog)s --user "azlm-prd-004@01ive.co.jp" --company "azlm-prd" --start "2025-09-04 23:00:00" --end "2025-09-04 23:30:00"
  
  # DynamoDBã®ã¿
  python %(prog)s --user "azlm-prd-004@01ive.co.jp" --start "2025-09-04 23:00:00" --end "2025-09-04 23:30:00"
  
  # Timestreamã®ã¿
  python %(prog)s --company "azlm-prd" --start "2025-09-04 23:00:00" --end "2025-09-04 23:30:00"
        """)
    
    parser.add_argument('--user', '-u', type=str, help='ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆDynamoDBç”¨ï¼‰')
    parser.add_argument('--company', '-c', type=str, help='ä¼šç¤¾IDï¼ˆä¸¡æ–¹ã§ä½¿ç”¨ï¼‰')
    parser.add_argument('--start', '-s', type=str, required=True, help='é–‹å§‹æ™‚é–“ï¼ˆYYYY-MM-DD HH:MM:SSå½¢å¼ï¼‰')
    parser.add_argument('--end', '-e', type=str, required=True, help='çµ‚äº†æ™‚é–“ï¼ˆYYYY-MM-DD HH:MM:SSå½¢å¼ï¼‰')
    parser.add_argument('--event', type=str, help='ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆDynamoDBç”¨ã€ä¾‹: face_detectedï¼‰')
    parser.add_argument('--timezone', type=int, default=9, help='ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆTimestreamç”¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 9ï¼ˆæ—¥æœ¬ï¼‰ï¼‰')
    parser.add_argument('--csv-key-path', type=str, default='shibo-chen_accessKeys.csv',
                        help='AWSã‚­ãƒ¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--region', type=str, default='ap-northeast-1',
                        help='AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³')
    
    return parser.parse_args()

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    args = parse_arguments()
    
    # çµ±åˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–
    downloader = OrganizedAWSDownloader(
        csv_key_path=args.csv_key_path,
        region_name=args.region
    )
    
    # åˆ©ç”¨å¯èƒ½ãªã‚µãƒ¼ãƒ“ã‚¹ç¢ºèª
    services = []
    if downloader.dynamodb_available:
        services.append("DynamoDB")
    if downloader.timestream_available:
        services.append("Timestream")
    
    if not services:
        print("âŒ åˆ©ç”¨å¯èƒ½ãªAWSã‚µãƒ¼ãƒ“ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    print(f"\nğŸ”— åˆ©ç”¨å¯èƒ½ã‚µãƒ¼ãƒ“ã‚¹: {', '.join(services)}")
    
    # çµ±åˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
    output_folder, saved_files = downloader.download_all_data(
        user_id=args.user,
        company=args.company,
        start_time=args.start,
        end_time=args.end,
        event_type=args.event,
        timezone_offset=args.timezone
    )
    
    if saved_files:
        print(f"\nâœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸï¼")
        print(f"ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€: {output_folder}")
        print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(saved_files)}")
        print(f"\nğŸ’¡ ãƒ•ã‚©ãƒ«ãƒ€å†…å®¹ã‚’ç¢ºèª: ls {output_folder}/")
    else:
        print(f"\nâŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print(f"ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã¯ä½œæˆã•ã‚Œã¾ã—ãŸ: {output_folder}")

if __name__ == "__main__":
    main()
